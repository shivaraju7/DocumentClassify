AAA BBB CCC DDD 

chmod 755 convert-to-stanford-classifier.csh
csh convert-to-stanford-classifier.csh

java -mx1800m -cp $STANFORD_CLASSIFIER_JAR edu.stanford.nlp.classify.ColumnDataClassifier -trainFile 20news-bydate-devtrain-stanford-classifier.txt -testFile 20news-bydate-devtest-stanford-classifier.txt -2.useSplitWords -2.splitWordsRegexp "\\s+"


QUICKSTART

COMMAND LINE INTERFACE
To classify the included example dataset cheeseDisease (in the examples directory), type the following at the command line while in the main classifier directory:

java -cp "*:." edu.stanford.nlp.classify.ColumnDataClassifier -prop examples/cheese2007.prop

This will classify the included test data, cheeseDisease.test, based on the probability that each example is a cheese or a disease, as calculated by a linear classifier trained on cheeseDisease.train.

The cheese2007.prop file demonstrates how features are specified.  The first feature in the file, useClassFeature,
indicates that a feature should be used based on class frequency in the training set.  Most other features are
calculated on specific columns of data in your tab-delimited text file.  For example, "1.useNGrams=true" indicates
that n-gram features should be created for the values in column 1 (numbering begins at 0!).  Note that you must
specify, for example, "true" in "1.useNGrams=true"; "1.useNGrams" alone will not cause n-gram features to be created.
N-gram features are character subsequences of the string in the column, for example, "t", "h", "e", "th", "he",
"the" from the word "the". You can also specify various other kinds of features such as just using the string value
as a categorical feature (1.useString=true) or splitting up a longer string into bag-of-words features
(1.splitWordsRegexp=[ ]  1.useSplitWords=true).  The prop file also allows a choice of printing and optimization
options, and allows you to specify training and test files (e.g., in cheese2007.prop under the "Training input"
comment).  See the javadoc for ColumnDataClassifier within the edu.stanford.nlp.classify package for more information
on these and other options.

Another included dataset is the iris dataset which uses numerical features to separate types of irises.   To specify the use of a real-valued rather than categorical feature, you can use one or more of "realValued", "logTransform", or "logitTransform" for a given column.  "realValued" adds the number in the given column as a feature value, while the transform options perform either a log or a logit transform on the value first.  The format of these feature options is the same as for categorical features; for instance, iris2007.prop shows the use of real valued features such as "2.realValued=true".

CLASSIFYING YOUR OWN DATA FILES
To classify your own data files, they should be in tab-delimited text from which to make features as shown above, SVMLight format, or as tab-delimited text with the exact feature values you would like.  Then specify the train and test files on the command line or in a .prop file with "trainFile=/myPath/myTrainFile.train" and "testFile==/myPath/myTestFile.test".  You can also create a serialized classifier using the serializeTo option followed by a file path.

CODE EXAMPLES
You can also directly use the classes in this package to train classifiers within other programs.  An example of this is shown in ClassifierExample, in the package edu.stanford.nlp.classify.  This class demonstrates how to build a classifier factory, creating a classifier and setting various parameters in the classifier, training the classifier, and finally testing the classifier on a different data set.

NO GUI
This package does not provide a graphical user interface.  The
classifier is accessible only via the command line or programmatically.
